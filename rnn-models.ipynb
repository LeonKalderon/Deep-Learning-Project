{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/allennlp/commands/find_learning_rate.py:55: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  import matplotlib; matplotlib.use('Agg')\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymagnitude import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import RNN, GRU, LSTM, Dense, Input, Embedding, Dropout, Activation, concatenate\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D, SimpleRNN\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from scipy import sparse\n",
    "from keras import backend as K # Importing Keras backend (by default it is Tensorflow)\n",
    "from keras.layers import Input, Dense # Layers to be used for building our model\n",
    "from keras.models import Model # The class used to create a model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils # Utilities to manipulate numpy arrays\n",
    "from tensorflow import set_random_seed # Used for reproducible experiments\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import InputLayer, Input, Embedding, Dense, Dropout, Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, SpatialDropout1D, Conv1D, CuDNNLSTM, CuDNNGRU, TimeDistributed, Reshape, Permute, LocallyConnected1D, concatenate, ELU, Activation, add, Lambda, BatchNormalization, PReLU, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "#from kgutil.models.keras.base import DefaultTrainSequence, DefaultTestSequence\n",
    "#from kgutil.models.keras.rnn import KerasRNN, load_emb_matrix\n",
    "from copy import deepcopy\n",
    "import inspect\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/Transformat data\n",
    "- Read dataset\n",
    "- Split comments(x) and categories(y)\n",
    "- Tokenize all the comment (take the max_features most frequent words of all the comments)\n",
    "- Pad each comment to max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/train.csv')\n",
    "test_data = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train_data[classes].values\n",
    "\n",
    "train_sentences = train_data[\"comment_text\"].fillna(\"fillna\").str.lower()\n",
    "test_sentences = test_data[\"comment_text\"].fillna(\"fillna\").str.lower()\n",
    "\n",
    "max_features = 150000\n",
    "max_len = 150\n",
    "embed_size = 300\n",
    "\n",
    "tokenizer = Tokenizer(max_features)\n",
    "tokenizer.fit_on_texts(list(train_sentences))\n",
    "\n",
    "tokenized_train_sentences = tokenizer.texts_to_sequences(train_sentences)\n",
    "tokenized_test_sentences = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "train_padding = pad_sequences(tokenized_train_sentences, max_len)\n",
    "test_padding = pad_sequences(tokenized_test_sentences, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings matrix\n",
    "- Download embeddings with Magnitude libray\n",
    "- Create an embedding_matrix dims: number_of_words x embeddings.dim with zero values\n",
    "- Fill the embedding_matrix with the embeddings with .query() Magnitude's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_len = 150\n",
    "#https://github.com/plasticityai/magnitude\n",
    "#!curl -s http://magnitude.plasticity.ai/glove+subword/glove.6B.300d.magnitude --output vectors.magnitude\n",
    "\n",
    "#vecs_word2vec = Magnitude('http://magnitude.plasticity.ai/word2vec/heavy/GoogleNews-vectors-negative300.magnitude', stream=True, pad_to_length=max_len) \n",
    "vecs_glove = Magnitude('http://magnitude.plasticity.ai/glove+subword/glove.6B.300d.magnitude')\n",
    "vecs_fasttext = Magnitude('http://magnitude.plasticity.ai/fasttext+subword/wiki-news-300d-1M.magnitude', pad_to_length=max_len)\n",
    "#vecs_elmo = Magnitude('http://magnitude.plasticity.ai/elmo/medium/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.magnitude', stream=True, pad_to_length=max_len)\n",
    "\n",
    "#vectors = Magnitude(vecs_fasttext, vecs_glove) # concatenate word2vec with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f1f695a38f45f88706f936ee14decf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=210337), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, vecs_glove.dim))\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = vecs_glove.query(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.uniform(-0.25, 0.25, embed_size)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Helpers\n",
    "Initialize the custome classes/functions that we'll need for our models\n",
    "\n",
    "- RocAuc metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/yekenot/pooled-gru-fasttext\n",
    "\n",
    "#Define a class for model evaluation\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, training_data=(),validation_data=()):\n",
    "        super(Callback, self).__init__()\n",
    "       \n",
    "        self.X_tra, self.y_tra = training_data\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.aucs_val = []\n",
    "        self.aucs_tra = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):                   \n",
    "        y_pred_val = self.model.predict(self.X_val, verbose=0)\n",
    "        score_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "\n",
    "        y_pred_tra = self.model.predict(self.X_tra, verbose=0)\n",
    "        score_tra = roc_auc_score(self.y_tra, y_pred_tra)\n",
    "\n",
    "        self.aucs_tra.append(score_tra)\n",
    "        self.aucs_val.append(score_val)\n",
    "        print(\"\\n ROC-AUC - epoch: %d - score_tra: %.6f - score_val: %.6f \\n\" % (epoch+1, score_tra, score_val))\n",
    "\n",
    "def recall(y_true, y_pred):    \n",
    "    \"\"\"\n",
    "    Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):    \n",
    "    \"\"\"\n",
    "    Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    Source\n",
    "    ------\n",
    "    https://github.com/fchollet/keras/issues/5400#issuecomment-314747992\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"Calculate the F1 score.\"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r))\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plots:\n",
    "    def plot_history(history):\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        x = range(1, len(val_loss) + 1)\n",
    "\n",
    "        plt.plot(x, loss, 'b', label='Training loss')\n",
    "        plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.legend()\n",
    "\n",
    "    def plot_roc_auc(train_roc, val_roc):\n",
    "        x = range(1, len(val_roc) + 1)\n",
    "\n",
    "        plt.plot(x, train_roc, 'b', label='Training RocAuc')\n",
    "        plt.plot(x, val_roc, 'r', label='Validation RocAuc')\n",
    "        plt.title('Training and validation RocAuc')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create models\n",
    "- BaseLine models https://realpython.com/python-keras-text-classification/\n",
    "- Single mode 98.18: https://github.com/ipcplusplus/toxic-comments-classification/blob/master/toxic_comment_analysis.ipynb\n",
    "- Attention Display : https://github.com/conversationai/conversationai-models/blob/master/attention-tutorial/Attention_Model_Tutorial.ipynb\n",
    "- Attention Models: https://github.com/thinline72/toxic/tree/master/skolbachev/toxic\n",
    "- Many models: https://github.com/neptune-ml/open-solution-toxic-comments\n",
    "- More modes alno: https://github.com/alno/kaggle-jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra, X_val, y_tra, y_val = train_test_split(train_padding, y, train_size=0.90, random_state=233)\n",
    "RocAuc = RocAucEvaluation(training_data=(X_tra, y_tra) ,validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN\n",
    "\n",
    "Text data have a sequence. Thus, the meaning of a word is dependant on the previous words. Thus, we will try to use RNN that uses the previous state of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143613/143613 [==============================] - 197s 1ms/step - loss: 0.3589 - acc: 0.9680 - binary_crossentropy: 0.3589 - val_loss: 0.5962 - val_acc: 0.9628 - val_binary_crossentropy: 0.5962\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59619, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score_tra: 0.509557 - score_val: 0.513197 \n",
      "\n",
      "Epoch 2/20\n",
      "143613/143613 [==============================] - 194s 1ms/step - loss: 0.5817 - acc: 0.9638 - binary_crossentropy: 0.5817 - val_loss: 0.5977 - val_acc: 0.9628 - val_binary_crossentropy: 0.5977\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.59619\n",
      "\n",
      " ROC-AUC - epoch: 2 - score_tra: 0.508895 - score_val: 0.511122 \n",
      "\n",
      "Epoch 3/20\n",
      "143613/143613 [==============================] - 195s 1ms/step - loss: 0.5821 - acc: 0.9638 - binary_crossentropy: 0.5821 - val_loss: 0.5977 - val_acc: 0.9628 - val_binary_crossentropy: 0.5977\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59619\n",
      "\n",
      " ROC-AUC - epoch: 3 - score_tra: 0.508368 - score_val: 0.511123 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16a4563a58>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(max_len, ))\n",
    "X = Embedding(max_features, embed_size, weights=[embedding_matrix])(input_layer)\n",
    "X = SimpleRNN(units=128, activation=\"relu\")(X)\n",
    "X = Dense(6, activation=\"sigmoid\")(X)\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "saved_model = \"weights_base.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2)\n",
    "callbacks_list = [checkpoint, early, RocAuc]\n",
    "\n",
    "batch_sz = 64\n",
    "epoch = 20\n",
    "\n",
    "model.fit(X_tra,\n",
    "          y_tra,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=batch_sz,\n",
    "          epochs=epoch,\n",
    "          callbacks=callbacks_list,\n",
    "          shuffle=True,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN\n",
    "From the simple RNN we saw that using the information from the previous state of the sequence helps, hence we will try to use a biRNN in order to use information that is not only before that token but also after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143613/143613 [==============================] - 45s 313us/step - loss: 0.0611 - acc: 0.9797 - binary_crossentropy: 0.0611 - val_loss: 0.0455 - val_acc: 0.9832 - val_binary_crossentropy: 0.0455\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04546, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score_tra: 0.987661 - score_val: 0.981955 \n",
      "\n",
      "Epoch 2/20\n",
      "143613/143613 [==============================] - 43s 296us/step - loss: 0.0358 - acc: 0.9859 - binary_crossentropy: 0.0358 - val_loss: 0.0442 - val_acc: 0.9832 - val_binary_crossentropy: 0.0442\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04546 to 0.04424, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score_tra: 0.996138 - score_val: 0.985598 \n",
      "\n",
      "Epoch 3/20\n",
      "143613/143613 [==============================] - 43s 297us/step - loss: 0.0253 - acc: 0.9900 - binary_crossentropy: 0.0253 - val_loss: 0.0509 - val_acc: 0.9821 - val_binary_crossentropy: 0.0509\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04424\n",
      "\n",
      " ROC-AUC - epoch: 3 - score_tra: 0.998564 - score_val: 0.983616 \n",
      "\n",
      "Epoch 4/20\n",
      "143613/143613 [==============================] - 43s 298us/step - loss: 0.0166 - acc: 0.9938 - binary_crossentropy: 0.0166 - val_loss: 0.0597 - val_acc: 0.9805 - val_binary_crossentropy: 0.0597\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04424\n",
      "\n",
      " ROC-AUC - epoch: 4 - score_tra: 0.999362 - score_val: 0.980379 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11e721c358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(max_len, ))\n",
    "X = Embedding(max_features, embed_size, weights=[embedding_matrix])(input_layer)\n",
    "X = Bidirectional(CuDNNGRU(128))(X)\n",
    "X = Dense(6, activation=\"sigmoid\")(X)\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "saved_model = \"weights_base.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2)\n",
    "callbacks_list = [checkpoint, early, RocAuc]\n",
    "\n",
    "batch_sz = 128\n",
    "epoch = 20\n",
    "\n",
    "model.fit(X_tra,\n",
    "          y_tra,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=batch_sz,\n",
    "          epochs=epoch,\n",
    "          callbacks=callbacks_list,\n",
    "          shuffle=True,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGRU with ebedding projection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143613/143613 [==============================] - 47s 324us/step - loss: 0.0533 - acc: 0.9805 - binary_crossentropy: 0.0533 - val_loss: 0.0429 - val_acc: 0.9838 - val_binary_crossentropy: 0.0429\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04293, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score_tra: 0.992879 - score_val: 0.986464 \n",
      "\n",
      "Epoch 2/20\n",
      "143613/143613 [==============================] - 44s 305us/step - loss: 0.0317 - acc: 0.9875 - binary_crossentropy: 0.0317 - val_loss: 0.0462 - val_acc: 0.9828 - val_binary_crossentropy: 0.0462\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04293\n",
      "\n",
      " ROC-AUC - epoch: 2 - score_tra: 0.997677 - score_val: 0.984982 \n",
      "\n",
      "Epoch 3/20\n",
      "143613/143613 [==============================] - 44s 305us/step - loss: 0.0207 - acc: 0.9920 - binary_crossentropy: 0.0207 - val_loss: 0.0557 - val_acc: 0.9813 - val_binary_crossentropy: 0.0557\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04293\n",
      "\n",
      " ROC-AUC - epoch: 3 - score_tra: 0.999062 - score_val: 0.981421 \n",
      "\n",
      "Epoch 4/20\n",
      "143613/143613 [==============================] - 44s 305us/step - loss: 0.0135 - acc: 0.9950 - binary_crossentropy: 0.0135 - val_loss: 0.0626 - val_acc: 0.9805 - val_binary_crossentropy: 0.0626\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04293\n",
      "\n",
      " ROC-AUC - epoch: 4 - score_tra: 0.999609 - score_val: 0.978612 \n",
      "\n",
      "Epoch 5/20\n",
      "143613/143613 [==============================] - 44s 305us/step - loss: 0.0093 - acc: 0.9968 - binary_crossentropy: 0.0093 - val_loss: 0.0740 - val_acc: 0.9804 - val_binary_crossentropy: 0.0740\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04293\n",
      "\n",
      " ROC-AUC - epoch: 5 - score_tra: 0.999798 - score_val: 0.977606 \n",
      "\n",
      "Epoch 6/20\n",
      "143613/143613 [==============================] - 44s 305us/step - loss: 0.0067 - acc: 0.9977 - binary_crossentropy: 0.0067 - val_loss: 0.0822 - val_acc: 0.9798 - val_binary_crossentropy: 0.0822\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04293\n",
      "\n",
      " ROC-AUC - epoch: 6 - score_tra: 0.999877 - score_val: 0.975979 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11e5da74a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(max_len, ))\n",
    "X = Embedding(max_features, embed_size, weights=[embedding_matrix])(input_layer)\n",
    "X = Dense(units=max_len, activation='relu')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Bidirectional(CuDNNGRU(128))(X)\n",
    "X = Dense(6, activation=\"sigmoid\")(X)\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "saved_model = \"weights_base.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks_list = [checkpoint, early, RocAuc]\n",
    "\n",
    "batch_sz = 128\n",
    "epoch = 20\n",
    "\n",
    "model.fit(X_tra,\n",
    "          y_tra,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=batch_sz,\n",
    "          epochs=epoch,\n",
    "          callbacks=callbacks_list,\n",
    "          shuffle=True,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGRU with MLP on top and embeddings projection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143613/143613 [==============================] - 47s 326us/step - loss: 0.0517 - acc: 0.9811 - binary_crossentropy: 0.0517 - val_loss: 0.0443 - val_acc: 0.9831 - val_binary_crossentropy: 0.0443\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04429, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score_tra: 0.993332 - score_val: 0.986613 \n",
      "\n",
      "Epoch 2/20\n",
      "143613/143613 [==============================] - 44s 306us/step - loss: 0.0322 - acc: 0.9870 - binary_crossentropy: 0.0322 - val_loss: 0.0462 - val_acc: 0.9832 - val_binary_crossentropy: 0.0462\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04429\n",
      "\n",
      " ROC-AUC - epoch: 2 - score_tra: 0.997458 - score_val: 0.985636 \n",
      "\n",
      "Epoch 3/20\n",
      "143613/143613 [==============================] - 44s 305us/step - loss: 0.0216 - acc: 0.9915 - binary_crossentropy: 0.0216 - val_loss: 0.0585 - val_acc: 0.9808 - val_binary_crossentropy: 0.0585\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04429\n",
      "\n",
      " ROC-AUC - epoch: 3 - score_tra: 0.999021 - score_val: 0.982467 \n",
      "\n",
      "Epoch 4/20\n",
      "143613/143613 [==============================] - 44s 306us/step - loss: 0.0142 - acc: 0.9946 - binary_crossentropy: 0.0142 - val_loss: 0.0719 - val_acc: 0.9804 - val_binary_crossentropy: 0.0719\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04429\n",
      "\n",
      " ROC-AUC - epoch: 4 - score_tra: 0.999573 - score_val: 0.979570 \n",
      "\n",
      "Epoch 5/20\n",
      "143613/143613 [==============================] - 44s 305us/step - loss: 0.0098 - acc: 0.9963 - binary_crossentropy: 0.0098 - val_loss: 0.0831 - val_acc: 0.9794 - val_binary_crossentropy: 0.0831\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04429\n",
      "\n",
      " ROC-AUC - epoch: 5 - score_tra: 0.999755 - score_val: 0.976403 \n",
      "\n",
      "Epoch 6/20\n",
      "143613/143613 [==============================] - 44s 306us/step - loss: 0.0073 - acc: 0.9973 - binary_crossentropy: 0.0073 - val_loss: 0.0993 - val_acc: 0.9797 - val_binary_crossentropy: 0.0993\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04429\n",
      "\n",
      " ROC-AUC - epoch: 6 - score_tra: 0.999857 - score_val: 0.974297 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11e4ecc588>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(max_len, ))\n",
    "X = Embedding(max_features, embed_size, weights=[embedding_matrix])(input_layer)\n",
    "# Embedding projection Layer before the RNN\n",
    "X = Dense(units=max_len, activation='relu')(X)\n",
    "# X = Dropout(0.2)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Bidirectional(CuDNNGRU(128))(X)\n",
    "# MLP on top of BiGRU\n",
    "X = Dense(256, activation='relu' )(X)\n",
    "# X = Dense(100, activation='relu' )(X)\n",
    "X = Dense(6, activation=\"sigmoid\")(X)\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "saved_model = \"weights_base.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks_list = [checkpoint, early, RocAuc]\n",
    "\n",
    "batch_sz = 128\n",
    "epoch = 20\n",
    "\n",
    "model.fit(X_tra,\n",
    "          y_tra,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=batch_sz,\n",
    "          epochs=epoch,\n",
    "          callbacks=callbacks_list,\n",
    "          shuffle=True,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143613/143613 [==============================] - 47s 329us/step - loss: 0.0528 - acc: 0.9807 - binary_crossentropy: 0.0528 - val_loss: 0.0441 - val_acc: 0.9833 - val_binary_crossentropy: 0.0441\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04409, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score_tra: 0.992439 - score_val: 0.986435 \n",
      "\n",
      "Epoch 2/20\n",
      "143613/143613 [==============================] - 44s 307us/step - loss: 0.0323 - acc: 0.9871 - binary_crossentropy: 0.0323 - val_loss: 0.0463 - val_acc: 0.9828 - val_binary_crossentropy: 0.0463\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04409\n",
      "\n",
      " ROC-AUC - epoch: 2 - score_tra: 0.997546 - score_val: 0.985154 \n",
      "\n",
      "Epoch 3/20\n",
      "143613/143613 [==============================] - 44s 307us/step - loss: 0.0215 - acc: 0.9915 - binary_crossentropy: 0.0215 - val_loss: 0.0556 - val_acc: 0.9810 - val_binary_crossentropy: 0.0556\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04409\n",
      "\n",
      " ROC-AUC - epoch: 3 - score_tra: 0.998994 - score_val: 0.981327 \n",
      "\n",
      "Epoch 4/20\n",
      "143613/143613 [==============================] - 44s 306us/step - loss: 0.0140 - acc: 0.9947 - binary_crossentropy: 0.0140 - val_loss: 0.0720 - val_acc: 0.9806 - val_binary_crossentropy: 0.0720\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04409\n",
      "\n",
      " ROC-AUC - epoch: 4 - score_tra: 0.999503 - score_val: 0.978127 \n",
      "\n",
      "Epoch 5/20\n",
      "143613/143613 [==============================] - 44s 306us/step - loss: 0.0097 - acc: 0.9963 - binary_crossentropy: 0.0097 - val_loss: 0.0850 - val_acc: 0.9793 - val_binary_crossentropy: 0.0850\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04409\n",
      "\n",
      " ROC-AUC - epoch: 5 - score_tra: 0.999770 - score_val: 0.975651 \n",
      "\n",
      "Epoch 6/20\n",
      "143613/143613 [==============================] - 44s 306us/step - loss: 0.0069 - acc: 0.9974 - binary_crossentropy: 0.0069 - val_loss: 0.0967 - val_acc: 0.9790 - val_binary_crossentropy: 0.0967\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04409\n",
      "\n",
      " ROC-AUC - epoch: 6 - score_tra: 0.999852 - score_val: 0.971957 \n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 150, 300)     45000000    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 150, 150)     45150       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 150, 150)     600         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) [(None, 150, 256), ( 215040      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional_4[0][1]            \n",
      "                                                                 bidirectional_4[0][2]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          65792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 6)            1542        dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 45,328,124\n",
      "Trainable params: 45,327,824\n",
      "Non-trainable params: 300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(max_len, ))\n",
    "X = Embedding(max_features, embed_size, weights=[embedding_matrix])(input_layer)\n",
    "# Embedding projection Layer before the RNN\n",
    "X = Dense(units=max_len, activation='relu')(X)\n",
    "# X = Dropout(0.2)(X)\n",
    "X = BatchNormalization()(X)\n",
    "x_state, x_fwd, x_bwd = Bidirectional(CuDNNGRU(128, return_sequences=True, return_state=True))(X)\n",
    "X = concatenate([x_fwd, x_bwd])\n",
    "# MLP on top of BiGRU\n",
    "# X = Reshape((2 * max_len,128, 1))(X)\n",
    "X = Dense(units=256, activation='relu')(X)\n",
    "X = Dense(6, activation=\"sigmoid\")(X)\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "saved_model = \"weights_base.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks_list = [checkpoint, early, RocAuc]\n",
    "\n",
    "batch_sz = 128\n",
    "epoch = 20\n",
    "\n",
    "model.fit(X_tra,\n",
    "          y_tra,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=batch_sz,\n",
    "          epochs=epoch,\n",
    "          callbacks=callbacks_list,\n",
    "          shuffle=True,\n",
    "          verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/80\n",
      "143613/143613 [==============================] - 59s 408us/step - loss: 0.1044 - val_loss: 0.0664\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06639, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score_tra: 0.960413 - score_val: 0.958003 \n",
      "\n",
      "Epoch 2/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0609 - val_loss: 0.0574\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06639 to 0.05745, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score_tra: 0.968417 - score_val: 0.966508 \n",
      "\n",
      "Epoch 3/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0553 - val_loss: 0.0563\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05745 to 0.05634, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score_tra: 0.971904 - score_val: 0.969387 \n",
      "\n",
      "Epoch 4/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0535 - val_loss: 0.0545\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05634 to 0.05453, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score_tra: 0.973486 - score_val: 0.970234 \n",
      "\n",
      "Epoch 5/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0518 - val_loss: 0.0530\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05453 to 0.05303, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score_tra: 0.975508 - score_val: 0.971958 \n",
      "\n",
      "Epoch 6/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0508 - val_loss: 0.0535\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05303\n",
      "\n",
      " ROC-AUC - epoch: 6 - score_tra: 0.976913 - score_val: 0.973527 \n",
      "\n",
      "Epoch 7/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0497 - val_loss: 0.0516\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05303 to 0.05160, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 7 - score_tra: 0.978154 - score_val: 0.974601 \n",
      "\n",
      "Epoch 8/80\n",
      "143613/143613 [==============================] - 56s 393us/step - loss: 0.0488 - val_loss: 0.0507\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05160 to 0.05069, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 8 - score_tra: 0.979941 - score_val: 0.976254 \n",
      "\n",
      "Epoch 9/80\n",
      "143613/143613 [==============================] - 57s 395us/step - loss: 0.0478 - val_loss: 0.0497\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05069 to 0.04968, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score_tra: 0.981188 - score_val: 0.977068 \n",
      "\n",
      "Epoch 10/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0468 - val_loss: 0.0487\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04968 to 0.04867, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 10 - score_tra: 0.982352 - score_val: 0.978519 \n",
      "\n",
      "Epoch 11/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0457 - val_loss: 0.0486\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04867 to 0.04864, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 11 - score_tra: 0.983959 - score_val: 0.979147 \n",
      "\n",
      "Epoch 12/80\n",
      "143613/143613 [==============================] - 56s 393us/step - loss: 0.0447 - val_loss: 0.0478\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04864 to 0.04784, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 12 - score_tra: 0.985032 - score_val: 0.980508 \n",
      "\n",
      "Epoch 13/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0437 - val_loss: 0.0468\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.04784 to 0.04680, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 13 - score_tra: 0.986301 - score_val: 0.981665 \n",
      "\n",
      "Epoch 14/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0426 - val_loss: 0.0468\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.04680 to 0.04680, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 14 - score_tra: 0.987205 - score_val: 0.982726 \n",
      "\n",
      "Epoch 15/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0419 - val_loss: 0.0464\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.04680 to 0.04636, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 15 - score_tra: 0.988104 - score_val: 0.983475 \n",
      "\n",
      "Epoch 16/80\n",
      "143613/143613 [==============================] - 56s 393us/step - loss: 0.0410 - val_loss: 0.0466\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04636\n",
      "\n",
      " ROC-AUC - epoch: 16 - score_tra: 0.988711 - score_val: 0.982027 \n",
      "\n",
      "Epoch 17/80\n",
      "143613/143613 [==============================] - 56s 393us/step - loss: 0.0402 - val_loss: 0.0467\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04636\n",
      "\n",
      " ROC-AUC - epoch: 17 - score_tra: 0.989494 - score_val: 0.983714 \n",
      "\n",
      "Epoch 18/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0397 - val_loss: 0.0458\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04636 to 0.04583, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 18 - score_tra: 0.989743 - score_val: 0.983655 \n",
      "\n",
      "Epoch 19/80\n",
      "143613/143613 [==============================] - 56s 393us/step - loss: 0.0386 - val_loss: 0.0466\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04583\n",
      "\n",
      " ROC-AUC - epoch: 19 - score_tra: 0.990543 - score_val: 0.983739 \n",
      "\n",
      "Epoch 20/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0381 - val_loss: 0.0449\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04583 to 0.04492, saving model to weights_base.best.hdf5\n",
      "\n",
      " ROC-AUC - epoch: 20 - score_tra: 0.991137 - score_val: 0.984455 \n",
      "\n",
      "Epoch 21/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0374 - val_loss: 0.0464\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04492\n",
      "\n",
      " ROC-AUC - epoch: 21 - score_tra: 0.991202 - score_val: 0.983648 \n",
      "\n",
      "Epoch 22/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0368 - val_loss: 0.0457\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04492\n",
      "\n",
      " ROC-AUC - epoch: 22 - score_tra: 0.991914 - score_val: 0.983545 \n",
      "\n",
      "Epoch 23/80\n",
      "143613/143613 [==============================] - 57s 394us/step - loss: 0.0361 - val_loss: 0.0456\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04492\n",
      "\n",
      " ROC-AUC - epoch: 23 - score_tra: 0.992145 - score_val: 0.983854 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11e2d55d30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_shape = 6\n",
    "lr=0.0003\n",
    "rnn_dropout=None\n",
    "rnn_layers=[128, 64]\n",
    "mlp_layers=[70]\n",
    "mlp_dropout=0.1\n",
    "text_emb_dropout=0.0\n",
    "text_emb_size=300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(name='comment_text', input_shape=[max_len]))\n",
    "model.add(Embedding(max_features, text_emb_size, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Dropout(text_emb_dropout))\n",
    "\n",
    "for layer_size in rnn_layers:\n",
    "    #Fast LSTM implementation backed by CuDNN. Can only be run on GPU, with the TensorFlow backend.\n",
    "    model.add(Bidirectional(CuDNNLSTM(layer_size, return_sequences=True)))\n",
    "    if rnn_dropout is not None:\n",
    "        model.add(SpatialDropout1D(rnn_dropout))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "for layer_size in mlp_layers:\n",
    "    model.add(Dense(layer_size, activation=\"relu\"))\n",
    "    model.add(Dropout(mlp_dropout))\n",
    "model.add(Dense(6, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.000015))\n",
    "\n",
    "saved_model = \"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
    "callbacks_list = [checkpoint, early, RocAuc]\n",
    "\n",
    "model.fit(x=X_tra,\n",
    "          y=y_tra,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=128,\n",
    "          epochs=80,         \n",
    "          callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8d19694bf5d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.summary() # Print a description of the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Plots.plot_roc_auc(RocAuc.aucs_tra, RocAuc.aucs_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPlots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# model.summary() # Print a description of the model.\n",
    "# Plots.plot_roc_auc(RocAuc.aucs_tra, RocAuc.aucs_val)\n",
    "Plots.plot_history(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fb4a5b85e071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_padding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_values = model.predict([test_padding], batch_size=1024, verbose=1)\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission[classes] = test_values\n",
    "sample_submission.to_csv('/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-22635ef21c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_download_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Download CSV file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_submission' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a link to download the dataframe which was saved with .to_csv method\n",
    "create_download_link(filename='submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-79954c2610f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "from IPython.display import Image\n",
    "Image(retina=True, filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ann_visualizer\r\n",
      "  Downloading https://files.pythonhosted.org/packages/db/51/157be500337fba347e32711aaf9f11c1ba9e1162f486a1d708b4ae594ea4/ann_visualizer-2.5.tar.gz\r\n",
      "Building wheels for collected packages: ann-visualizer\r\n",
      "  Building wheel for ann-visualizer (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/b6/b4/4e/d92f50c9c4f004cf315a0e0fcd455486bd799c50fe80cf1f5d\r\n",
      "Successfully built ann-visualizer\r\n",
      "Installing collected packages: ann-visualizer\r\n",
      "Successfully installed ann-visualizer-2.5\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.6/site-packages (0.8.4)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (2.9.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py) (1.12.0)\r\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.6/site-packages (from h5py) (1.16.4)\r\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xdg-open': 'xdg-open'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8f3945477fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mann_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Artificial Neural network - Model Visualization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/ann_visualizer/visualize.py\u001b[0m in \u001b[0;36mann_viz\u001b[0;34m(model, view, filename, title)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrowhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#707070\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mview\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mview\u001b[0;34m(self, filename, directory, cleanup)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m    202\u001b[0m         return self.render(filename=filename, directory=directory, view=True,\n\u001b[0;32m--> 203\u001b[0;31m                            cleanup=cleanup)\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, filename, directory, view, cleanup)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrendered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrendered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36m_view\u001b[0;34m(self, filepath, format)\u001b[0m\n\u001b[1;32m    216\u001b[0m             raise RuntimeError('%r has no built-in viewer support for %r '\n\u001b[1;32m    217\u001b[0m                 'on %r platform' % (self.__class__, format, backend.PLATFORM))\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mview_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0m_view_darwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdarwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mview_unixoid\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mview_unixoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;34m\"\"\"Open filepath in the user's preferred application (linux, freebsd).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xdg-open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xdg-open': 'xdg-open'"
     ]
    }
   ],
   "source": [
    "!pip install ann_visualizer\n",
    "!pip install graphviz\n",
    "!pip install h5py\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "ann_viz(model, title=\"Artificial Neural network - Model Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bdcc7d8d338b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04531ea3d2b44721a7ad581af9c30c22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3ab481d758d2441fa73b92aa653312c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b3b10d41dd94b1b9f5b41dfed76abc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3ab481d758d2441fa73b92aa653312c1",
       "placeholder": "",
       "style": "IPY_MODEL_04531ea3d2b44721a7ad581af9c30c22",
       "value": " 38% 79467/210337 [06:32&lt;15:12, 143.37it/s]"
      }
     },
     "69d339aad2b74503a3e9c2fd24edcd21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9a84d59275994d079ba1463a826c8a24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb7907761cc5446daceb037d33ad7798": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.1.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.1.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.1.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4f1f695a38f45f88706f936ee14decf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f99765409b1d44cf9a58813c9f74041d",
        "IPY_MODEL_3b3b10d41dd94b1b9f5b41dfed76abc2"
       ],
       "layout": "IPY_MODEL_9a84d59275994d079ba1463a826c8a24"
      }
     },
     "f99765409b1d44cf9a58813c9f74041d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.4.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.4.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.4.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb7907761cc5446daceb037d33ad7798",
       "max": 210337,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_69d339aad2b74503a3e9c2fd24edcd21",
       "value": 79483
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
